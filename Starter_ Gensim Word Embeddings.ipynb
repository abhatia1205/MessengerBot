{"cells":[{"metadata":{"_uuid":"4382cdf6-2f14-49a2-b7ab-8d5cfc4b1ca7","_cell_guid":"e3556c6a-f3cf-41a6-8ff5-ede0af3c7be8","trusted":true},"cell_type":"code","source":"# %% [markdown]\n# # Hello\n# \n# I put some popular word embeddings into a single Kaggle dataset in unified gensim format. Models are binarized, so they are quick to load (data is stored in numpy arrays).\n# \n# Why:\n# * Unified format - single handling function for different embeddings\n# * gensim mdoels are nice - a lot of helpful methods, take `most_similar` for example\n# * Fast loading!\n\n# %% [code] {\"_kg_hide-input\":false}\nfrom gensim.models import KeyedVectors\n\n# As of Gensim 3.7.3 it's using some deprecated function and we don't care about it\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# %% [code] {\"_kg_hide-input\":false}\nmodel = KeyedVectors.load(\"../input/glove.twitter.27B.200d.gensim\")\n\n# %% [markdown]\n# Glove in 4 seconds! But if you think that's impressive, hold my beer:\n\n# %% [code]\nmodel = KeyedVectors.load(\"../input/glove.twitter.27B.200d.gensim\", mmap=\"r\")\n\n# %% [markdown]\n# This is tiny `mmap=\"r\"` tells gensim/numpy to read bytes from the [disk directly to memory](https://en.wikipedia.org/wiki/Mmap). It just can't get faster than that.\n# \n# And now we can play around with vectors:\n\n# %% [code]\ndef most_similar_list(s, l):\n    temp= []\n    for i in l:\n        x = (i, model.n_similarity(s.split(), i.split()))\n        print(x)\n        temp.append(x)\n    temp = sorted(temp, key = lambda x: x[1], reverse = True)  \n    return temp\nl = [\"delete\", \"unsubscribe\", \"subscribe\", \" poll\", \"schedule\", \"post\"]\n\n\n\n# %% [code]\n#Pre Condition: Given 4 inputs: New Text, Set of Users, \n#Set of Channels and queue of previous texts and predictions\n# 1) Sentiment Analysis\n# 2) User and Channel Look Up\n# 3) POS Tagging\n# 4) USer, Channel, and Verb findinf\n# 5) Action determination using weights\n# Post Condition: Returns a dicitonary with original text, recommended action list, recommended action\n# sentiment value,set of found users and set of found channels\nclass NLPPipeline():\n    class FixedQueue():\n        def __init__(self,s):\n            self.queue = []\n            self.size = s\n        def push(self, x):\n            if(len(sel.queue) < 5):\n                self.queue.append(x)\n            else:\n                self.queue.pop(0)\n                self.queue.append(x)\n        def get(ind):\n            return self.queue[-1*ind - 1]\n        \n    def __init__(self,users, channels):\n        self.past_texts = FixedQueue(3)\n        self.users = users\n        self.channels = channels\n        \n    def process_text(self, text):\n        previous_sentiment_value = __processPrevSentiment() # type: int context: value representing weighted average of previous sentiment values\n        currentSentiment = __sentimentAnalysis(text) # type: int context: value representing this text's sentiment\n        uc_look_up = __userChannelLookUp(text) # type: dictionary with keys = {user, channel} and values = {list(users), list(channels)}\n        POS_dict = __POSTagging(text)\n        found_user_dict = __findUsers(uc_look_up, POS_dict, text)\n        found_channel_dict = __findChannels(uc_look_up, POS_dict, text)\n        verbRecommendations = __verbFinding(POS_dict, text)\n        actionDetermination = __determineAction()\n        \n        \n        \n        \n\n# %% [code]\nprint(most_similar_list(\"make event\",l ))\n\n# %% [code]\n","execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}